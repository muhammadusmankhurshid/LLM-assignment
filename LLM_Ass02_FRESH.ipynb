{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision transformers datasets matplotlib pandas scikit-learn wordcloud\n",
    "!pip install --upgrade --force-reinstall fsspec datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "plt.style.use('seaborn-v0_8-ticks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(\"Using device:\", device)\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample_balanced(df, n_per_class):\n",
    "    return (\n",
    "        df.groupby('label', group_keys=False)\n",
    "        .apply(lambda x: x.sample(n=n_per_class, random_state=42))\n",
    "        .reset_index(drop=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_distribution(df, colors):\n",
    "    plt.figure(figsize=(5,3))\n",
    "    df['label'].value_counts().plot(kind='bar', color=colors, edgecolor='#18020c')\n",
    "    plt.title('IMDB Class Balance', fontsize=13, color='#560bad')\n",
    "    plt.xlabel('Sentiment (0=Neg, 1=Pos)')\n",
    "    plt.ylabel('Count')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_length_histogram(df, color):\n",
    "    plt.figure(figsize=(6,2.8))\n",
    "    df['num_words'] = df['text'].apply(lambda t: len(t.split()))\n",
    "    plt.hist(df['num_words'], bins=30, color=color, edgecolor='#22223b', alpha=0.85)\n",
    "    plt.title('Review Word Count Distribution', fontsize=11, color='#fb8b24')\n",
    "    plt.xlabel('Words')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wordcloud(df, label, cmap, title, tcolor):\n",
    "    text_blob = \" \".join(df[df['label'] == label]['text'])\n",
    "    wc = WordCloud(width=700, height=200, background_color='white', colormap=cmap).generate(text_blob)\n",
    "    plt.figure(figsize=(7,2.6))\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(title, fontsize=12, color=tcolor)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_dataset(texts, labels, tokenizer, maxlen):\n",
    "    class IMDBBertDataset(Dataset):\n",
    "        def __init__(self, texts, labels, tokenizer, maxlen):\n",
    "            self.texts = texts\n",
    "            self.labels = labels\n",
    "            self.tokenizer = tokenizer\n",
    "            self.maxlen = maxlen\n",
    "        def __len__(self):\n",
    "            return len(self.texts)\n",
    "        def __getitem__(self, idx):\n",
    "            enc = self.tokenizer(\n",
    "                str(self.texts[idx]),\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                max_length=self.maxlen,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            batch = {k: v.squeeze(0) for k, v in enc.items()}\n",
    "            batch['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "            return batch\n",
    "    return IMDBBertDataset(texts, labels, tokenizer, maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bert(model, loader, optimizer, device, epochs):\n",
    "    model.train()\n",
    "    loss_history = []\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in loader:\n",
    "            ids = batch['input_ids'].to(device)\n",
    "            mask = batch['attention_mask'].to(device)\n",
    "            labs = batch['labels'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(input_ids=ids, attention_mask=mask, labels=labs)\n",
    "            loss = out.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(loader)\n",
    "        loss_history.append(avg_loss)\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.4f}\")\n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_loss(loss_history, color):\n",
    "    plt.figure(figsize=(6,3.2))\n",
    "    plt.plot(range(1, len(loss_history)+1), loss_history, marker='s', color=color, linewidth=2)\n",
    "    plt.title('Training Loss Curve', fontsize=13, color='#00b4d8')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_bert(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_true = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            ids = batch['input_ids'].to(device)\n",
    "            mask = batch['attention_mask'].to(device)\n",
    "            labs = batch['labels'].to(device)\n",
    "            outs = model(input_ids=ids, attention_mask=mask)\n",
    "            preds = torch.argmax(outs.logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_true.extend(labs.cpu().numpy())\n",
    "    return np.array(all_true), np.array(all_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(true_labels, pred_labels, class_names, cmap):\n",
    "    cm = confusion_matrix(true_labels, pred_labels)\n",
    "    fig, axis = plt.subplots(figsize=(5.5,4.5))\n",
    "    cm_disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    cm_disp.plot(cmap=cmap, ax=axis, colorbar=True)\n",
    "    plt.title('IMDB Confusion Matrix', fontsize=14, color='#3c096c')\n",
    "    plt.xlabel('Predicted', fontsize=12, color='#fb8b24')\n",
    "    plt.ylabel('True', fontsize=12, color='#fb8b24')\n",
    "    plt.xticks(fontsize=11, color='#212529')\n",
    "    plt.yticks(fontsize=11, color='#212529')\n",
    "    plt.grid(False)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_random_preds(test_texts, test_labels, pred_labels, n=5):\n",
    "    idxs = random.sample(range(len(test_texts)), n)\n",
    "    print(\"\\nRandom sample predictions:\")\n",
    "    for idx in idxs:\n",
    "        snippet = test_texts[idx][:90].replace('\\n', ' ')\n",
    "        print(f\"\\nReview: {snippet}...\")\n",
    "        print(f\"True: {'Positive' if test_labels[idx] == 1 else 'Negative'} | Predicted: {'Positive' if pred_labels[idx] == 1 else 'Negative'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MAIN WORKFLOW ---\n",
    "def main():\n",
    "    # Device\n",
    "    device = get_device()\n",
    "\n",
    "    # Data\n",
    "    imdb_raw = load_dataset(\"imdb\")\n",
    "    reviews_train_df = pd.DataFrame(imdb_raw['train'])\n",
    "    reviews_test_df = pd.DataFrame(imdb_raw['test'])\n",
    "\n",
    "    # Balanced, small subsample for speed\n",
    "    reviews_train_df = subsample_balanced(reviews_train_df, 3000)\n",
    "    reviews_test_df = subsample_balanced(reviews_test_df, 400)\n",
    "\n",
    "    # Visualization\n",
    "    plot_class_distribution(reviews_train_df, ['#5fa8d3', '#f07167'])\n",
    "    plot_length_histogram(reviews_train_df, '#06d6a0')\n",
    "    plot_wordcloud(reviews_train_df, 0, 'cool', 'Word Cloud: Negative Reviews', '#012a4a')\n",
    "    plot_wordcloud(reviews_train_df, 1, 'autumn', 'Word Cloud: Positive Reviews', '#ae2012')\n",
    "\n",
    "    # Tokenizer and datasets\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    max_len = 128\n",
    "\n",
    "    train_dataset = get_bert_dataset(reviews_train_df['text'].tolist(), reviews_train_df['label'].tolist(), tokenizer, max_len)\n",
    "    test_dataset = get_bert_dataset(reviews_test_df['text'].tolist(), reviews_test_df['label'].tolist(), tokenizer, max_len)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=12, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=12)\n",
    "\n",
    "    # Model, optimizer\n",
    "    model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2).to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "    # Training\n",
    "    loss_history = train_bert(model, train_loader, optimizer, device, epochs=10)\n",
    "    plot_training_loss(loss_history, '#f07167')\n",
    "\n",
    "    # Evaluation\n",
    "    y_true, y_pred = evaluate_bert(model, test_loader, device)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    print(f\"\\nTest Accuracy: {acc:.4f}\")\n",
    "    print(f\"Test F1 Score: {f1:.4f}\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    plot_cm(y_true, y_pred, ['Negative', 'Positive'], cmap='YlGnBu')\n",
    "\n",
    "    # Print 5 random predictions\n",
    "    print_random_preds(reviews_test_df['text'].tolist(), reviews_test_df['label'].tolist(), y_pred, n=5)\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
